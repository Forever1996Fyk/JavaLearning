## <center>RocketMQ 相关问题</center>

### 1. 如何解决顺序消费和重复消费

**`RocketMQ`在主题上是无序的, 它只有在队列层面才是保证有序的。** 


#### 1.1 顺序消费

顺序消费中一般有两种模式: **普通顺序和严格顺序。**

- 普通顺序是指消费者通过**同一个消费队列收到的消息是有顺序的, 不同消息队列收到的消息可能是无顺序的。**
普通顺序消息在 **`Broker`重启情况下不会保证消息顺序性(短暂时间)。**

- 严格殊勋是指消费者收到的所有消息均是顺序的。**即使在异常情况下也会保证消息的顺序性。**

严格顺序模式看起来很好, 但是实现它会付出很大的代价。如果使用严格顺序模式, `Broker`集群中只要有一台机器不可用, 则整个集群都不可用。现在主要场景也就用在`binlog`同步。

一般情况下, 我们的MQ都是能容忍短暂的乱序, 所以推荐使用普通顺序模式。

现在问题来了, 如果我们采用了**普通顺序模式**, 我们之前已经知道了`Producer`生产消息时会进行轮询(取决于负载均衡策略)来向同一主题的不同消息队列发送消息。

> 如果此时有几个消息分别是同一个订单的创建, 支付, 发货, 在轮询的策略下这`三个消息会被发送到不同的队列`, 而在不同队列中就无法使用`RocketMQ`的保证消息的有序性, 怎么解决?

![RocketMQ_messageOrder](/distributed/MQ/img/RocketMQ_messageOrder.jpg)

其实很简单, 我们需要处理的仅仅是将同一语义下的消息放入同一个队列(比如这里的同一个订单), 那我们可以使用**Hash取模法**来保证同一个订单在同一个队列中就行了。

#### 1.2 重复消费

首先解决重复消费的办法就两个字 ———— **幂等**。**在编程中`幂等`操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。**

例如: 有一个订单的处理积分的系统, 每当来一个消息的时候它就负责为创建这个订单的用户积分加上相应的数值。现在消息队列发送给订单系统user1的订单消息, 要求是给user1的积分加上500。但是积分系统在收到user1的订单消息处理完成之后, 返回给消息队列处理成功的响应时出现了网络波动,或者`Broker`意外重启等等, 这条响应没有发送成功。

那么, 消息队列没有收到这个积分系统的响应会不会尝试重发这个消息?如果重新发送, 万一它又给user1加上500积分怎么办?

针对上面出现的情况就需要给消费者实现**幂等**, 也就是对同一个消息的处理结果, 执行多少次都不变。

实现**幂等**的方式需要根据具体的业务来决定的。

- 写入`Redis`来保证, 因为`Redis`的`key`和`value`就是天然支持幂等的;
- 数据库插入法, 基于数据库的唯一键来保证重复数据不会被插入多条。

在整个互联网领域, **幂等**不仅仅适用于消息队列的重复消费问题, 还有很多其他的场景来解决重复请求或者重复调用的问题。比如将HTTP服务设计成幂等的, **解决前端或者APP重复提交表单数据的问题**, 也可以将一个微服务设计成幂等的, 解决`RPC`框架自动重试导致的**重复调用问题。**

### 2. 消息堆积问题

我们之前学习了为什么要使用消息队列, 其中一个很重要的功能————**削峰**。但是如果这个峰值太大了导致消息堆积在队列中怎么办?

其实这个问题可以将它广义化, **因为生产消息堆积的根源只有两个————生产者生产太快或者消费者消费太慢**。

所以解决这个问题可以从多个角度去思考, 当流量到峰值的时候是因为生产者生产太快, 我们可以使用一些**限流降级**的方法, 当然也可以增加多个消费者实例去水平扩展增加消费能力来匹配生产的激增。

如果消费者消费过慢的话, 我们可以先检查**是否是消费者出现了大量的消费错误**, 或者打印日志查看是否哪一个线程卡死, 出现了锁资源不释放等问题。

> 最快解决消息堆积问题的方法还是增加消费者实例, 不过你还需要同时增加每个主题的队列数量。因为在`RocketMQ`中, **一个队列只会被一个消费者消费**, 如果仅仅增加哦消费者实例就会出现消费位移错误的情况。

### 3. 回溯消费

回溯消费是指`Consumer`已经消费成功的消息, 由于业务上需求需要重新消费。在`RockeetMQ`中, `Broker`在向`Consumer`投递成功消息后, **消息仍然需要保留。**并且重新消费一般是按照时间维度, 例如: 由于`Consumer`系统故障, 恢复后需要重新消费1小时前的数据, 那么`Broker`要提供一种机制, 可以按照时间维度来回退消费进度。`RocketMQ`支持按照时间回溯消费, 时间维度精确到毫秒。

### 4. RocketMQ的刷盘机制

#### 4.1 同步刷盘和异步刷盘

![rocket_flush_disk](/distributed/MQ/img/rocket_flush_disk.jpg)

根据图示, 在同步刷盘中需要等待一个刷盘成功的`ACK`, 同步刷盘对`MQ`的消息可靠性来说是很好的保障, 但是**性能上会有较大的影响**, 一般适用于金融等特定业务场景。

异步刷盘往往是开启一个线程去异步的执行刷盘操作。消息刷盘采用后台异步线程提交的方式进行, **降低了读写延迟**, 提高了`MQ`的性能和吞吐量, 一般适用于发送验证码等对于消息保证要求不太高的业务场景。

在一般情况下, **异步刷盘只有在`Broker`意外宕机的时候会丢失部分数据**, 你可以设置`Broker`的参数`FlushDiskType`来调整你的刷盘策略(ASYNC_FLUSH或者SYNC_FLUSH)。

#### 4.2 同步复制和异步复制

上面的同步刷盘和异步刷盘实在单个节点层面的, 而同步复制和异步复制主要是在`Broker`主从模式下, 主节点返回消息给客户端的时候是否需要同步从节点。

- 同步复制: 也叫"同步双写", 也就是说, **只有消息同步双写到主从节点上时才返回写入成功。**
- 异步复制: **消息写入主节点之后就直接返回写入成功。**

> 异步复制会不会也像异步刷盘那样影响消息的可靠性呢?

答案是不会的, 因为两者就是不同的概念, 对于消息可靠性是通过不同的刷盘策略保证的, 而像异步同步复制策略仅仅是影响到**可用性**。
其最主要原因是 **`RocketMQ`是不支持自动主从切换的, 当主节点挂掉之后, 生产者就不能再给这个主节点生产消息了**。

例如: 采用异步复制的方式, 在主节点还未发送完需要同步的消息的时候主节点宕机了, 这个时候从节点就少了一部分消息。但是此时生产者无法再给主节点生产消息了, **消费者可以自动切换到从节点进行消费(仅仅是消费)**, 所以在主节点宕机的时间内只会产生主从节点短暂的消息不一致的情况, 降低了可用性, 而当主节点重启之后, 从节点丢失的消息还会继续复制。

在单一的主从架构中, 如果主节点挂掉了, 那也就意味着整个系统不能再生产了, 那么可用性如何解决? **一个主从不行那就多个主从。** 每个`Topic`是分布在不同的`Broker`中的。

但是这样也会带来一个问题, 那就是无法保证**严格顺序**。如果此时我们主节点A负责的是订单A的一系列消息, 然后它宕机了, 这样其他节点是无法代替主节点A的, 如果我们任意节点都可以存入任何消息, 那就没有顺序性可言了。

在`RocketMQ`中采用了`Dledger`解决这个问题。它要求在写入消息的时候, 要求**至少消息复制到半数以上的节点之后**, 才给客户端返回写入成功, 并且它是支持通过选举来动态切换主节点的。

### 5. 存储机制

> 在`Topic`中**队列是以什么样的形式存在的? 队列中的消息有事如何进行存储持久化的呢?**

`RocketMQ`消息存储架构中的三大角色-- `CommitLog`, `ConsumeQueue`, `IndesFile`。

- `CommitLog`: **消息主体以及元数据的存储主体**, 存储`Producer`端写入消息主体内容, 消息内容不是固定的。单个文件大小默认1G, 文件名长度为20位(为什么要设计成固定的? 内存映射机制), 左边补零, 剩余为起始偏移量, 比如00000000000000000000代表第一个文件, 起始偏移量为0, 文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。 消息主要是**顺序写入日志文件**, 当文件满了, 写入下一个文件。

- `ConsumeQueue`: 消息消费队列, 引入的目的主要是**提高消息的消费性能**, 由于`RocketMQ`是基于主题的`Topic`的订阅模式, 消息消费是针对主题进行的, 如果要遍历`CommitLog`文件中根据`Topic`检索消息是非常低效的。`Consumer`即可根据`ConsumeQueue`来查找待消费的消息。**`ConsumeQueue`作为消费消息的索引, 保存了指定`Topic`下的队列消息在`CommitLog`中的起始物理偏移量`offset`, 消息大小`size`和消息`Tag`的`HashCode`值。**

- `IndexFile`: `IndexFile`(索引文件)提供了一种可以通过key或时间区间来查询消息的方法。

`RocketMQ`采用的是**混合型的存储结构**, `Broker`单个实例下所有的队列共用一个日志数据文件在存储消息。因为这个可以**提高数据的写入效率**, 不分`Topic`意味着我们有更大的几率获取**成批**的消息进行数据写入, 但是也会导致读取消息的时候需要遍历整个大文件十分耗时的问题。

所以在`RocketMQ`中又使用`ConsumeQueue`作为每个队列的索引文件来**提升读取消息的效率**。我们可以直接根据队列的消息序号, 计算出索引的全局位置(索引序号*索引固定长度20), 然后直接读取这条索引, 再根据索引中记录的消息全局位置找到消息。

![rocket_message_storage](distributed/MQ/img/rocket_message_storage.jpg)

根据上图, 基本上就知道了`RocketMQ`的存储消费过程了。

生成者发送消息会指定`Topic`, `QueueId`和具体消息内容, 而在`Broker`中不管什么消息, 他直接全部存储到`CommitLog`中, 而根据生成者指定的`Topic`和`QueueId`将这条消息本身在`CommitLog`的偏移(offset), 消息本身大小, 和`tag`的hash值存入对应的`ConsumeQueue`索引文件中。

在每个队列中都保存了`ConsumeOffset`, 即每个消费者组的消费位置, 而消费者拉取消息进行消费的时候只需要根据`ConsumeOffset`获取下一个未被消费消息即可。

### 6. 分布式消息中心(总结)

#### 6.1 消息丢失的问题

1. 当系统需要保证百分百消息不丢失, 可以使用生成者每发送一个消息, `Broker`同步返回一个消息发送成功的反馈消息
2. 每发送一个消息, 同步落盘后才返回生产者消息发送成功, 这样只要生产者得到了消息发送生成的返回, 事后除了硬盘损坏, 都可以保证不会消息丢失。
3. 但是同步落盘怎么样才能快?

#### 6.2 同步落盘怎么才能快

1. 使用`FileChannel + DirectBuffer池`, 使用堆外内存, 加快内存拷贝
2. 使用数据和索引分离, 当消息需要写入时, 使用`CommitLog`文件顺序写入, 当需要定位某个消息时, 查询`IndexFile`文件来定位, 从而减少文件IO随机读写的性能损耗

#### 6.3 消息堆积的问题

1. 后台定时任务每隔72小时, 删除旧的没有使用过的消息信息
2. 根据不同的业务实现不同的丢弃任务, 参考线程池的`AbortPolicy`, 例如`FIFO/LRU`等(RocketMQ没有此策略)
3. 消息定时转移, 或者对某些重要的TAG型(支付型)消息真正落库

#### 6.4 定时消息的实现

1. `RocketMQ`没有实现任意精度的定时消息, 他只支持某些特定的时间精度的定时消息
2. 定时消息的原理是: **创建特定时间精度的`MessageQueue`, 例如生产者需要定时1s之后被消费者消费, 你只需要将此消息发送到特定的`Topic`, MessageQueue-1 表示这个 MessageQueue 里面的消息都会延迟一秒被消费，然后 Broker 会在 1s 后发送到消费者消费此消息，使用 newSingleThreadScheduledExecutor 实现。**

#### 6.5 顺序消息的实现

1. 与定时消息同原理，生产者生产消息时指定特定的 MessageQueue ，消费者消费消息时，消费特定的 MessageQueue，其实单机版的消息中心在一个 MessageQueue 就天然支持了顺序消息
2. 注意：同一个 MessageQueue 保证里面的消息是顺序消费的前提是：消费者是串行的消费该 MessageQueue，因为就算 MessageQueue 是顺序的，但是当并行消费时，还是会有顺序问题，但是串行消费也同时引入了两个问题：

> 1. 引入锁来实现串行
> 2. 前一个消费阻塞时后面都会被阻塞

#### 6.6 分布式消息的实现

1. 前提需要知道: 2PC
2. `RocketMQ4.3`支持, 原理是2PC, 即两阶段提交, `prepared->commit/rollback`
3. 生产者发送事务消息, 假设该事务消息`Topic`为`Topic1-Trans`, `Broker`得到后首先更改该消息的`Topic`为`Topic1-Prepared`, 该`Topic1-Prepared`对消费者不可见。然后定时回调生产者的本地事务A执行状态, 根据本地事务A执行状态, 来判断是否将该消息修改为`Topic1-Commit`或`Topic1-Rollback`, 消费者就可以正常找到该事务消息或者不执行等。


#### 6.7 消息的push实现

1. 注意: `RocketMQ`会有低延迟问题, 其中包括了消息的push延迟问题
2. 因为这并不是真正的将消息主动的推送到消费者, 而是`Broker`定时任务每5s将消息推送到消费者

#### 6.8 消息重复发送的避免

1. `RocketMQ`会出现消息重复发送的问题, 因为在网络延迟的情况下, 这种问题不可避免, 如果非要实现消息不可重复发送, 基本上不可能, 因为网络环境无法预知, 还会使程序复杂度增加, 因此默认允许消息重复发送
2. `RocketMQ`让使用者在消费者端去解决该问题, 即需要消费者端在消费信息时支持幂等性的去消费信息
3. 最简单的解决方案是**没条消费记录有一个消费状态字段, 根据这个消费状态字段来判断是否消费或者使用一个集中式的表来存储所有消息的消费状态, 从而避免重复消费**
4. 具体实现可以查询关于消息幂等消费的解决方案

#### 6.9 广播消费与集群消费

1. 消息消费区别: 广播消费, 订阅该`Topic`的消息者们都会消费每个消息。集群消息, 订阅该`Topic`的消息者们只会有一个去消费某个消息
2. 消息落盘区别: 具体表现在消息消费进度的保存上。广播消费, 由于每个消费者都独立的去消费每个消息, 因此每个消费各自都保存自己的消息消费进度。而集群模式下, 订阅了某个`Topic`, 而又有多个`MessageQueue`, 每个消费者都可能会去消费不同的`MessageQueue`, 因此总体的消费进度保存在`Broker`上集中的管理。

#### 6.10 RocketMQ不适用ZooKeeper作为注册中心的原因, 以及自制的NameServer优缺点?

1. `ZooKeeper`作为支持顺序一致性的中间件, 在某些情况下, 为了满足一致性, 会丢失一定时间内的可用性, `RocketMQ`需要注册中心只是为了发现组件地址, 在某些情况下, `RocketMQ`的注册中心可以出现数据不一致性, 这同时也是NameServer的缺点, 因为NameServer集群间互不通信, 他们之间的注册信息可能回不一致
2. 另外, 当有新的服务器加入时, NameServer并不会立马通知到Producer, 而是有Producer定时去请求NameServer获取最新的`Broker/Consumer`信息(这种情况是通过 Producer 发送消息时，负载均衡解决)