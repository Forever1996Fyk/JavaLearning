## HashMap相关面试题

之前学习了`HashMap`, 趁着还没忘, 从网上收集一些`HashMap`相关的面试题。

### 1. HashMap的数据结构是什么?

`HashMap`是基于哈希表的结构实现的, 也就是数组+链表。结合了数组和链表的优点。在JDK1.8之后, 还加入了红黑树, 当链表的长度超过8时, 链表会转换为红黑树。

### 2. HashMap的工作原理是什么?

`HashMap`底层是hash数组和单向链表实现, 数组中的每个元素都封装成Node节点, Node实现了`Map.Entry`接口, `HashMap`通过put & get方法存储和获取。

**存储对象时, 将key, value 键值对通过put方法传入:**

1. 调用`hash(key)`方法计算key的hash值, 然后结合数组长度, 计算数组下标; 具体算法就是把hash值与数组长度减一进行按位与运算, `hash & (length - 1)`;

2. 调整数组大小, 当容器中的元素个数大于`capacity * loadfactor`时, 容器会进行扩容调用`resize`方法, 扩容为原来的2倍;

3. 判断key的hash值在`HashMap`中是否存在:

    - 如果不存在则直接插入到数组下标位置;

    - 如果存在, 再判断key值是否相等, 也就是调用equals方法。 如果不存在, 则直接覆盖原value的值, 否则说明发生了哈希碰撞;

    - 发生哈希碰撞, 再判断相应位置的元素是否是`TreeNode`类型, 如果不是, 则表示当前是链表结构, 那就直接在链表的尾部插入元素, 如果链表的长度大于8时, 就将链表的结构树化; 如果当前位置元素类型是`TreeNode`, 则说明当前数据结构是红黑树, 那就将元素插入到红黑树中。

**获取对象是, 将key值传给get()方法:**

1. 调用hash(key)方法计算key的hash值, 然后再次进行计算数组下标;
2. 获取当前位置的Node元素, 通过equals方法判断当前元素的key值是否相同:

    - 如果相同则直接返回value值;

    - 如果不相同, 则判断Node的next节点是否为空;  如果不为空, 再判断Node类型是否是`TreeNode`, 如果是, 则遍历红黑树, 查找元素; 否则遍历链表

通过hashCode可以获取到哈希表的下标, 存储位置; equals比较两个key是否相等

### 3. 当两个对象的hashcode相同会发生什么?

因为对象的hashCode相同, 不一定就是相等的, 所以两个对象所在的数组下标相同, 可能会发生碰撞。

### 4. HashMap中hash函数的实现是怎样的? 为什么要这样实现?

在JDK1.8中, 是通过hashcode的高16位与hashcode的低16位进行异或运算, `(h = key.hashCode()) ^ (h >>> 16)`。主要从速度和减少hash碰撞的问题考虑。

### 5. 为什么要用异或运算符?

使用异或运算, 主要是保证对象的hashCode的32位, 只要有一位发生改变, 整个hash()返回值就会改变, 尽可能的减少碰撞。

### 6. HashMap的table容量如何确定? loadFactor是什么? 该容量如何变化? 这种变化会带来什么问题>

1. hash表的大小是由capacity参数确定的, 默认大小是16, 也可以通过构造函数传入, 最大限制是1<<30;

2. `loadFactor`是装载因子, 主要目的就是用来确认table数组是否需要动态扩展, 默认值是0.75。

    > 比如table数组大小为16, 装载因子为0.75时, threshold就是12。当table的实际大小超过12时, table就需要进行扩容

3. 扩容时调用`resize`方法, 将table长度变为原来的2倍;

4. 当数据量很大的情况下, 由于在扩容后, 还需要对原hash表进行遍历, 重新分配元素的位置; 这就会导致性能的损失。

### 7. HashMap中put方法的过程/原理?

1. 调用`hash(key)`方法计算key的hash值, 然后结合数组长度, 计算数组下标; 具体算法就是把hash值与数组长度减一进行按位与运算, `hash & (length - 1)`;

2. 调整数组大小, 当容器中的元素个数大于`capacity * loadfactor`时, 默认是16 * 0.75, 容器会进行扩容调用`resize`方法, 扩容为原来的2倍;

3. 判断key的hash值在`HashMap`中是否存在:

    - 如果不存在则直接插入到数组下标位置;

    - 如果存在, 再判断key值是否相等, 也就是调用equals方法。 如果不存在, 则直接覆盖原value的值, 否则说明发生了哈希碰撞;

    - 发生哈希碰撞, 再判断相应位置的元素是否是`TreeNode`类型, 如果不是, 则表示当前是链表结构, 那就直接在链表的尾部插入元素, 如果链表的长度大于8时, 就将链表的结构树化; 如果当前位置元素类型是`TreeNode`, 则说明当前数据结构是红黑树, 那就将元素插入到红黑树中。

![collection_hashmap_put](/image/collection_hashmap_put.png)

### 8. HashMap扩容的过程?

1. 创建一个新的数组, 其容量是旧数组的2倍(`newCap = oldCap << 1`), 同时扩展长度也变为原来的2倍(`newThr = oldThr << 1`);

2. 当扩容大小确定时, 遍历原来的table, 将原table中的每个元素放入到新table中;

3. 如果元素Node的next节点为null, 也就是说不存在链表以及红黑树的情况下, 根据hash值重新计算新数组的下标位置, 放入到新table中。 其中`e.hash & (newCap - 1)`就是计算原来的元素e在新table中的位置;

4. 如果元素Node的类型是`TreeNode`, 就表示此时该位置上存在红黑树, 那就需要重新调整红黑树的结构, 如果树的size很小, 默认是6, 那就将红黑树退化成链表;

5. 如果该位置的数据结构是链表, 那就重新计算元素的位置下标。链表节点在新数组中的位置下标只有两种: 一种是原下标的位置, 一种是原下标加上旧数组的长度;

    > 通过将元素的hash值与旧数组的长度进行按位与`&`运算, 结果只有两种: 一种是等于0, 一种是大于0; <br>
    > 当结果等于0, 就直接使用原数组的下标; 当结果大于0, 就是原下标加上旧数组的长度的值, 作为新数组的下标。<br>
    > 因为数组的长度必须是2的n次幂减一, 在二进制中高位为0, 低位为1的表示, 这样跟元素的hash值进行与运算, 所得到的的结果, 就只有两种。要么等于0, 要么大于0。<br>

    假设table原长度是16, 扩容后长度就是32, 那么一个hash值在扩容前后的table下标计算如下:

    ![collection_hashmap_resize](/image/collection_hashmap_resize.png)

    从图中可以看到, 链表中元素的hash值, 与新旧table的长度进行按位与运算的结果, 最后四位显然是相同的, 唯一可能出现的区别的地方就在第5位, 也就是hash值b所在的位置, 如果b所在的位置是运算结果是0, 那么这个元素的位置与新table相同, 反之如果b所在的位置是1, 则新table重新计算的位置结果就比原来的位置多了10000(二进制), 而这个二进制10000的结果就是旧table的长度16。

    所以在代码中`e.hash & oldCap`, 链表元素的hash值与旧table的长度进行按位与`&`运算的结果。 如果最终结果是0, 则表示新下标就等于原下标, 如果不等于那么新下标等于旧下标的长度加上当前元素的位置。

### 9. 为什么HashMap不用平衡二叉树(AVL), 而选择红黑树(RB Tree)? 而且为什么不直接使用红黑树, 而是先使用链表?

1. 首先不选二叉查找树, 就是因为二叉查找树在特殊情况下, 会导致树的高度很深, 变成一条线性结构, 这就跟原来的链表一样了, 遍历查找非常影响效率;

2. 引入红黑树是为了解决链表过长, 导致查找元素时, 需要遍历链表, 效率很低的问题。

但是红黑树是平衡二叉树在插入新元素时, 可能需要通过左旋, 右旋, 变色的操作来保持平衡, 但是由于, 所以要保持平衡也是需要进行操作, 但是这些操作比遍历很长的链表效率要高。如果链表长度很短的话, 根本不需要引入红黑树, 引入反而会慢。

### 10. 说说你对红黑树的理解?

1. 每个节点非红即黑

2. 根节点总是黑色的

3. 如果节点是红色的，则它的子节点必须是黑色的(反之不一定)

4. 每个叶子节点都是黑色的空节点(NIL节点)

5. 从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点(即相同的黑色高度)

### 11. HashMap, LinkedHashMap, TreeMap有什么区别?

- `HashMap`: 在Map中插入, 删除和定位元素时, 常用。

- `LinkedHashMap`: 当需要输出的顺序和输入顺序相同的情况下使用

- `TreeMap`: 当需要按照key的自然顺序或者自定义顺序遍历key的情况下使用; 自定义顺序就是实现`Comparable`接口

### 12. 构造HashMap时, 如果传入的初始容量值不是2的n次幂怎么办?

`HashMap`中对传入的初始化容量参数进行校验, 如果不是2的n次幂, 就通过一定的方法, 找到大于这个值的最近的2的n次幂。

具体的方法: 

因为我们发现`2^n-1`的值二进制, 低位都是1, 其他位都是0, 所以将原值通过无符号右移分别右移1次, 2次, 4次, 8次, 16次 并且 每次右移在与之前的值进行或运算`|`, 然后可以得到`2^n-1`的二进制, 最后再加1即可。

### 13. 为什么HashMap的容量一定是2的n次幂?

`HashMap`中的hash算法是:

```java
hashcode & (length - 1)
```

其中length就是数组长度, hash就是插入值的hash值, 如果length=2^n的话, 那么length-1 = 2^n-1。

我们通过上面的示例分析可以看到, 2^n-1用二进制表示, 所有位一定都是1, 此时跟hash值进行`&`与运算, 则可以完整保留原来的hash值的二进制数据。这样基本上很少会出现hash碰撞, 因为只要插入的key不相同, 基本上就不会出现hash碰撞。(除非hash值比较相近)

相反的, 如果数组长度不是2的n次幂, 则出现hash碰撞的可能性会大大提高。如下图示例:

![collection_hashmap_tablesize2n](/image/collection_hashmap_tablesize2n.png)

还有一点, **在数组扩容时, 扩容的数组长度是原来的2倍。假设初始oldCap=4, 要扩容到newCap=8时, 在二进制中就是 0100 到 1000的变化, 也就是左移一位就是2倍。**

### 14. HashMap为什么用红黑树而不用AVL(平衡二叉树), 或者B+树?

AVL是一个高度平衡的二叉查找树, 它虽然保证了搜索, 插入, 删除操作平均的时间复杂度都是O(log n), 但是增加和删除可能需要通过一次或多次的旋转来重新平衡这个树。

但是红黑树并不追求完美, 它只要求部分平衡, 降低旋转的要求。

红黑树是牺牲了严格的高度平衡为代价, 来提升性能。

> 红黑树常常不会单独使用, 而是与数组关联。也就是类似`HashMap`的实现方式。`TreeMap`和`TreeSet`的实现底层都是直接通过红黑树算法, 也就意味着`TreeMap`添加元素, 取出元素的性能都比`HashMap`低。

`TreeMap`添加元素, 都需要通过循环找到新增的Entry插入位置, 因此比较消耗性能, 而取出元素, 也需要遍历树。

所以合理的使用红黑树可以提高性能, 反正可能回影响性能。


### 15. HashMap和HashTable有什么区别?

1. `HashMap`是线程不安全的, `HashTable`是线程安全的;
2. `HashMap`最多允许一条记录的键为null, 允许多条记录的值为null, 但是`HashTable`不允许;
3. `HashMap`默认初始化数组的大小为16, `HashTable`为11, 前者扩容时, 大小为原来的2倍, 后者扩大2倍加1;
4. `HashMap`需要重新计算hash值, 而`HashTable`直接使用对象的hashCode。

### 16. Java中另一个线程安全的与`HashMap`极其类似的类是什么? 同样是线程安全的, 它与`HashTable`在线程同步上有什么不同?

这个类是`ConcurrentHashMap`类。在JDK1.7中采用分段锁的方式, JDK1.8中直接采用CAS的方式。

而`HashTable`是直接通过`synchronized`关键字加锁。

### 17. 针对 ConcurrentHashMap 锁机制具体分析(JDK 1.7 VS JDK 1.8)?

### 18. ConcurrentHashMap在JDK1.8中, 为什么要使用内置锁synchronized来代替重入锁ReentrantLock?

### 19. ConcurrentHashMap 简单介绍?

### 20. ConcurrentHashMap 的并发度是什么?




